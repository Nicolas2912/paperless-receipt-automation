feat(flow): add SQLite index and backlog processing

Introduce processed_index.py with SQLite DB (paperless_db/paperless.sqlite3)
to track processed files by content hash. Enables restart-proof dedupe and
startup backlog processing for scans added during downtime.

Integrate DB into main_paperless_flow.py:
- Initial sync with Paperless using original_filename and title prefix
- Backlog sweep: process unindexed JPEGs immediately on startup
- Record uploads with file hash and backfill paperless_doc_id
- Resolve doc_id via task polling; fallback by original_filename
- Polling tuned: 3s initial delay, 0.5s interval, 45s deadline with error log

Also fixes regex bug in task parsing and adds robust logging.

User-visible impact: newly added scans during downtime are processed on
startup like normal; previously processed files are skipped safely.
